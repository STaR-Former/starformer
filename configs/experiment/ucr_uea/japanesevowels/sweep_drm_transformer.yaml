# @package _global_
dataset: japanesevowels

defaults:
  - override /callbacks/lr_scheduler: reduceLROnPlateau
  - override /callbacks/early_stop: ucr_uea
  - override /callbacks/model_ckpt: ucr_uea
  - override /datamodule: ucr_uea/japanesevowels/centralized
  - override /logger: wandb
  - override /loss: ce
  - override /model: drm_transformer
  - override /optimizer: adam
  - override /training: ucr_uea/centralized
  

training:
  epochs: 300 #50
model:
  embedding:
    d_features: 12 
    max_seq_len: 26
  output_head:
    batch_size: ${training.batch_size} 
    d_out: 9
logger:
  project: japanesevowels_sweeps
  sweep: true
datamodule:
  s3_bucket_path: null 
callbacks:
  lr_scheduler:
    patience: 8
  model_ckpt:
    monitor: val/loss
    mode: min

  
  
  
