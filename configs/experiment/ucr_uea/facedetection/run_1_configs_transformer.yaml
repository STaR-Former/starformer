model:
  d_model: 8
  activation: 'silu'
  dim_feedforward: 16
  dropout: 0.18051489434056545
  n_head: 2
  num_encoder_layers: 4 #2 
optimizer:
  beta1: 0.8619376088654916
  beta2: 0.9106556855417052
  weight_decay: 0.0003398346224692972
training:
  learning_rate: 0.0008698428814571452
  batch_size: 16
