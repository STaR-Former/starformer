# @package _global_
dataset: pam

defaults:
  - override /callbacks/lr_scheduler: reduceLROnPlateau
  - override /callbacks/early_stop: pam
  - override /callbacks/model_ckpt: pam
  - override /datamodule: pam/centralized
  - override /logger: wandb
  - override /loss: ce
  - override /model: drm_transformer
  - override /optimizer: adam
  - override /training: pam/centralized
  

training:
  epochs: 300 
model:
  embedding:
    d_features: 17
    max_seq_len: 241
  output_head:
    batch_size: ${training.batch_size} 
    d_out: 8
logger:
  project: pam_sweeps
  sweep: true
datamodule:
  s3_bucket_path: null
callbacks:
  lr_scheduler:
    patience: 8
  
  
  
